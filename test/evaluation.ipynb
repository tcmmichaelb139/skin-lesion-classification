{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    img = img/255.0\n",
    "    \n",
    "    pre = v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    return pre(img)\n",
    "\n",
    "def create_dataset(file_dir):\n",
    "    return ImageFolder(\n",
    "        root = file_dir,\n",
    "        loader = torchvision.io.read_image,\n",
    "        transform=preprocessing\n",
    "    )\n",
    "\n",
    "dataset_name = [\"hiba\", \"isic2019\", \"ham10000\", \"pad_ufes_20\"]\n",
    "\n",
    "datasets = {}\n",
    "for name in dataset_name:\n",
    "    datasets[name] = create_dataset(f\"./datasets/individual/{name}\")\n",
    "datasets[\"test\"] = create_dataset(f\"./datasets/test\")\n",
    "dataset_name.append(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = dict()\n",
    "for name in dataset_name:\n",
    "    dataloader[name] = DataLoader(datasets[name], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "class JointModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.name = model\n",
    "\n",
    "        model = torchvision.models.get_model(model, weights=\"DEFAULT\")\n",
    "\n",
    "        self.m = copy.deepcopy(model)\n",
    "\n",
    "        self.ffnn = nn.Sequential(\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(512, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.m(x)\n",
    "    \n",
    "        ret = self.ffnn(x)\n",
    "        ret = self.classifier(ret)\n",
    "\n",
    "        return ret\n",
    "\n",
    "models = [\n",
    "    JointModel(model=\"shufflenet_v2_x2_0\"),\n",
    "    JointModel(model=\"convnext_tiny\"),\n",
    "    JointModel(model=\"efficientnet_v2_s\"),\n",
    "]\n",
    "\n",
    "for i in range(len(models)):\n",
    "    models[i] = models[i].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    models[i].load_state_dict(torch.load(f\"./save_models/{models[i].name}.pt\"))\n",
    "\n",
    "for i in range(len(models)):\n",
    "    for param in models[i].parameters():\n",
    "        param.requires_grad = False\n",
    "    models[i].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembledModel(\n",
       "  (ffnn): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Dropout(p=0.5, inplace=False)\n",
       "    (15): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EnsembledModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.models = copy.deepcopy(models)\n",
    "        \n",
    "        for i in range(len(self.models)):\n",
    "            self.models[i].classifier = nn.Identity()\n",
    "\n",
    "        self.ffnn = nn.Sequential(\n",
    "             nn.Linear(512 + 512 + 512, 2048),\n",
    "             nn.ReLU(),\n",
    "             nn.Dropout(),\n",
    "             nn.Linear(2048, 1024),\n",
    "             nn.ReLU(),             \n",
    "             nn.Dropout(),\n",
    "             nn.Linear(1024, 1024),\n",
    "             nn.ReLU(),\n",
    "             nn.Dropout(),\n",
    "             nn.Linear(1024, 1024),\n",
    "             nn.ReLU(),\n",
    "             nn.Dropout(),\n",
    "             nn.Linear(1024, 1024),\n",
    "             nn.ReLU(),\n",
    "             nn.Dropout(),\n",
    "             nn.Linear(1024, 5),\n",
    "         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.models[0](x)\n",
    "        x2 = self.models[1](x)\n",
    "        x3 = self.models[2](x)\n",
    "        x = torch.cat([x1, x2, x3], dim=1)\n",
    "        x = self.ffnn(x)\n",
    "        return x\n",
    "    \n",
    "model = EnsembledModel([models[i] for i in range(len(models))])\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./save_models/ensemble/ensembled.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:09<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shufflenet_v2_x2_0\n",
      "['83.814', '76.078', '73.626', '74.384', '94.256', '95.518']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:10<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext_small\n",
      "['84.720', '79.630', '73.371', '76.204', '94.207', '96.134']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:11<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_v2_s\n",
      "['85.238', '78.038', '74.767', '76.035', '94.846', '96.026']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:20<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model\n",
      "['88.184', '84.953', '79.116', '81.534', '95.776', '96.211']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model,hiba Dataset\n",
      "['74.074', '67.090', '61.384', '63.093', '92.070', '90.388']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:17<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model,isic2019 Dataset\n",
      "['89.126', '86.727', '80.892', '83.497', '95.742', '96.530']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model,ham10000 Dataset\n",
      "['91.813', '92.048', '75.230', '81.164', '94.206', '95.992']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model,pad_ufes_20 Dataset\n",
      "['85.022', '80.282', '71.868', '74.463', '95.583', '92.742']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from imblearn import metrics as immetrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "disease_labels = [\n",
    "    \"actinic keratosis\",\n",
    "    \"basal cell carcinoma\",\n",
    "    \"melanoma\",\n",
    "    \"squamous cell carcinoma\",\n",
    "    \"others\"\n",
    "]\n",
    "\n",
    "\n",
    "def prediction(model, testloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    predictions_prob = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            output = torch.nn.functional.softmax(output, dim=1)\n",
    "            predictions.append(output.max(dim=1)[1])\n",
    "            actual.append(labels)\n",
    "            predictions_prob.append(output)\n",
    "\n",
    "    actual = torch.concat(actual).cpu()\n",
    "    predictions = torch.concat(predictions).cpu()\n",
    "    predictions_prob = torch.concat(predictions_prob).cpu()\n",
    "\n",
    "    return predictions, predictions_prob, actual\n",
    "    \n",
    "def display_results(name, model, loader, device):\n",
    "    predictions, predictions_prob, actual = prediction(model, loader, device)\n",
    "\n",
    "    print(name)\n",
    "    ret = [\n",
    "        metrics.accuracy_score(actual, predictions),\n",
    "        metrics.precision_score(actual, predictions, average='macro'),\n",
    "        metrics.recall_score(actual, predictions, average='macro'),\n",
    "        metrics.f1_score(actual, predictions, average='macro'),\n",
    "        immetrics.specificity_score(actual, predictions, average=\"macro\"),\n",
    "        metrics.roc_auc_score(actual, predictions_prob, average=\"macro\", multi_class=\"ovr\")\n",
    "    ]\n",
    "    \n",
    "    return ['%.3f' % (n*100) for n in ret]\n",
    "\n",
    "    \n",
    "print(display_results(\"shufflenet_v2_x2_0\", models[0], dataloader[\"test\"], device))\n",
    "print(display_results(\"convnext_small\", models[1], dataloader[\"test\"], device))\n",
    "print(display_results(\"efficientnet_v2_s\", models[2], dataloader[\"test\"], device))\n",
    "print(display_results(\"Ensemble Model\", model, dataloader[\"test\"], device))\n",
    "dataset_name = [\"hiba\", \"isic2019\", \"ham10000\", \"pad_ufes_20\"]\n",
    "\n",
    "for name in dataset_name:\n",
    "    print(display_results(f\"Ensemble Model,{name} Dataset\", model, dataloader[name], device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m122"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5228198,
     "sourceId": 8714424,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
